torch.Size([3, 480, 720])
Using device: cuda
FPN(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (toplayer): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
  (toplayer2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  (toplayer3): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))
  (up): Upsample(scale_factor=2.0, mode=bilinear)
  (smooth1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (smooth2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (smooth3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (latlayer1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
  (latlayer2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
  (latlayer3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
)
Epoch [1/100], Step [10/1050], Loss: 6.6266
Epoch [1/100], Step [20/1050], Loss: 2.5218
Epoch [1/100], Step [30/1050], Loss: 1.0979
Epoch [1/100], Step [40/1050], Loss: 0.9589
Epoch [1/100], Step [50/1050], Loss: 0.6581
Epoch [1/100], Step [60/1050], Loss: 0.4777
Epoch [1/100], Step [70/1050], Loss: 0.6206
Epoch [1/100], Step [80/1050], Loss: 0.4141
Epoch [1/100], Step [90/1050], Loss: 0.3240
Epoch [1/100], Step [100/1050], Loss: 0.3318
Epoch [1/100], Step [110/1050], Loss: 0.3056
Epoch [1/100], Step [120/1050], Loss: 0.2979
Epoch [1/100], Step [130/1050], Loss: 0.2726
Epoch [1/100], Step [140/1050], Loss: 0.2193
Epoch [1/100], Step [150/1050], Loss: 0.3661
Epoch [1/100], Step [160/1050], Loss: 0.2787
Epoch [1/100], Step [170/1050], Loss: 0.3344
Epoch [1/100], Step [180/1050], Loss: 0.3580
Epoch [1/100], Step [190/1050], Loss: 0.1737
Epoch [1/100], Step [200/1050], Loss: 0.1462
Epoch [1/100], Step [210/1050], Loss: 0.2257
Epoch [1/100], Step [220/1050], Loss: 0.2067
Epoch [1/100], Step [230/1050], Loss: 0.1493
Epoch [1/100], Step [240/1050], Loss: 0.1274
Epoch [1/100], Step [250/1050], Loss: 0.1283
Epoch [1/100], Step [260/1050], Loss: 0.1150
Epoch [1/100], Step [270/1050], Loss: 0.1118
Epoch [1/100], Step [280/1050], Loss: 0.1473
Epoch [1/100], Step [290/1050], Loss: 0.1317
Epoch [1/100], Step [300/1050], Loss: 0.1732
Epoch [1/100], Step [310/1050], Loss: 0.0967
Epoch [1/100], Step [320/1050], Loss: 0.1103
Epoch [1/100], Step [330/1050], Loss: 0.1125
Epoch [1/100], Step [340/1050], Loss: 0.0799
Epoch [1/100], Step [350/1050], Loss: 0.1672
Epoch [1/100], Step [360/1050], Loss: 0.0886
Epoch [1/100], Step [370/1050], Loss: 0.1230
Epoch [1/100], Step [380/1050], Loss: 0.1632
Epoch [1/100], Step [390/1050], Loss: 0.0872
Epoch [1/100], Step [400/1050], Loss: 0.2059
Epoch [1/100], Step [410/1050], Loss: 0.0989
Epoch [1/100], Step [420/1050], Loss: 0.1458
Epoch [1/100], Step [430/1050], Loss: 0.1407
Epoch [1/100], Step [440/1050], Loss: 0.0807
Epoch [1/100], Step [450/1050], Loss: 0.0693
Epoch [1/100], Step [460/1050], Loss: 0.0751
Epoch [1/100], Step [470/1050], Loss: 0.0742
Epoch [1/100], Step [480/1050], Loss: 0.0904
Epoch [1/100], Step [490/1050], Loss: 0.0796
Epoch [1/100], Step [500/1050], Loss: 0.0679
Epoch [1/100], Step [510/1050], Loss: 0.0853
Epoch [1/100], Step [520/1050], Loss: 0.1274
Epoch [1/100], Step [530/1050], Loss: 0.1053
Epoch [1/100], Step [540/1050], Loss: 0.1174
Epoch [1/100], Step [550/1050], Loss: 0.0768
Epoch [1/100], Step [560/1050], Loss: 0.0662
Epoch [1/100], Step [570/1050], Loss: 0.0968
Epoch [1/100], Step [580/1050], Loss: 0.0776
Epoch [1/100], Step [590/1050], Loss: 0.0799
Epoch [1/100], Step [600/1050], Loss: 0.0518
Epoch [1/100], Step [610/1050], Loss: 0.1447
Epoch [1/100], Step [620/1050], Loss: 0.1125
Epoch [1/100], Step [630/1050], Loss: 0.0895
Epoch [1/100], Step [640/1050], Loss: 0.0785
Epoch [1/100], Step [650/1050], Loss: 0.0538
Epoch [1/100], Step [660/1050], Loss: 0.0462
Epoch [1/100], Step [670/1050], Loss: 0.0812
Epoch [1/100], Step [680/1050], Loss: 0.0667
Epoch [1/100], Step [690/1050], Loss: 0.0613
Epoch [1/100], Step [700/1050], Loss: 0.0420
Epoch [1/100], Step [710/1050], Loss: 0.0503
Epoch [1/100], Step [720/1050], Loss: 0.0539
Epoch [1/100], Step [730/1050], Loss: 0.0608
Epoch [1/100], Step [740/1050], Loss: 0.0524
Epoch [1/100], Step [750/1050], Loss: 0.0546
Epoch [1/100], Step [760/1050], Loss: 0.0536
Epoch [1/100], Step [770/1050], Loss: 0.1328
Epoch [1/100], Step [780/1050], Loss: 0.1017
Epoch [1/100], Step [790/1050], Loss: 0.0495
Epoch [1/100], Step [800/1050], Loss: 0.0479
Epoch [1/100], Step [810/1050], Loss: 0.0774
Epoch [1/100], Step [820/1050], Loss: 0.0524
Epoch [1/100], Step [830/1050], Loss: 0.0425
Epoch [1/100], Step [840/1050], Loss: 0.0422
Epoch [1/100], Step [850/1050], Loss: 0.0398
Epoch [1/100], Step [860/1050], Loss: 0.1047
Epoch [1/100], Step [870/1050], Loss: 0.0423
Epoch [1/100], Step [880/1050], Loss: 0.0478
Epoch [1/100], Step [890/1050], Loss: 0.0521
Epoch [1/100], Step [900/1050], Loss: 0.0314
Epoch [1/100], Step [910/1050], Loss: 0.0358
Epoch [1/100], Step [920/1050], Loss: 0.0640
Epoch [1/100], Step [930/1050], Loss: 0.0399
Epoch [1/100], Step [940/1050], Loss: 0.0400
Epoch [1/100], Step [950/1050], Loss: 0.0513
Epoch [1/100], Step [960/1050], Loss: 0.0363
Epoch [1/100], Step [970/1050], Loss: 0.0440
Epoch [1/100], Step [980/1050], Loss: 0.0334
Epoch [1/100], Step [990/1050], Loss: 0.0342
Epoch [1/100], Step [1000/1050], Loss: 0.0413
Epoch [1/100], Step [1010/1050], Loss: 0.0332
Epoch [1/100], Step [1020/1050], Loss: 0.0813
Epoch [1/100], Step [1030/1050], Loss: 0.0336
Epoch [1/100], Step [1040/1050], Loss: 0.0488
Epoch [1/100], Step [1050/1050], Loss: 0.0486
torch.Size([3, 480, 720])
Using device: cuda
FPN(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (toplayer): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
  (toplayer2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  (toplayer3): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))
  (up): Upsample(scale_factor=2.0, mode=bilinear)
  (smooth1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (smooth2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (smooth3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (latlayer1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
  (latlayer2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
  (latlayer3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
)
Epoch [1/100], Step [10/1050], Loss: 6.5890
Epoch [1/100], Step [20/1050], Loss: 2.4858
Epoch [1/100], Step [30/1050], Loss: 1.1119
Epoch [1/100], Step [40/1050], Loss: 0.9212
Epoch [1/100], Step [50/1050], Loss: 0.6554
Epoch [1/100], Step [60/1050], Loss: 0.4901
Epoch [1/100], Step [70/1050], Loss: 0.6387
Epoch [1/100], Step [80/1050], Loss: 0.4508
Epoch [1/100], Step [90/1050], Loss: 0.3526
Epoch [1/100], Step [100/1050], Loss: 0.3342
Epoch [1/100], Step [110/1050], Loss: 0.2931
Epoch [1/100], Step [120/1050], Loss: 0.2928
Epoch [1/100], Step [130/1050], Loss: 0.2830
Epoch [1/100], Step [140/1050], Loss: 0.2130
Epoch [1/100], Step [150/1050], Loss: 0.3591
Epoch [1/100], Step [160/1050], Loss: 0.2765
Epoch [1/100], Step [170/1050], Loss: 0.3271
Epoch [1/100], Step [180/1050], Loss: 0.3430
Epoch [1/100], Step [190/1050], Loss: 0.1652
Epoch [1/100], Step [200/1050], Loss: 0.1518
Epoch [1/100], Step [210/1050], Loss: 0.2263
Epoch [1/100], Step [220/1050], Loss: 0.2031
Epoch [1/100], Step [230/1050], Loss: 0.1410
Epoch [1/100], Step [240/1050], Loss: 0.1289
Epoch [1/100], Step [250/1050], Loss: 0.1268
Epoch [1/100], Step [260/1050], Loss: 0.1093
Epoch [1/100], Step [270/1050], Loss: 0.1125
Epoch [1/100], Step [280/1050], Loss: 0.1495
Epoch [1/100], Step [290/1050], Loss: 0.1339
Epoch [1/100], Step [300/1050], Loss: 0.1758
Epoch [1/100], Step [310/1050], Loss: 0.0965
Epoch [1/100], Step [320/1050], Loss: 0.1220
Epoch [1/100], Step [330/1050], Loss: 0.1201
Epoch [1/100], Step [340/1050], Loss: 0.0831
Epoch [1/100], Step [350/1050], Loss: 0.1652
Epoch [1/100], Step [360/1050], Loss: 0.0927
Epoch [1/100], Step [370/1050], Loss: 0.1234
Epoch [1/100], Step [380/1050], Loss: 0.1542
Epoch [1/100], Step [390/1050], Loss: 0.0795
Epoch [1/100], Step [400/1050], Loss: 0.2089
Epoch [1/100], Step [410/1050], Loss: 0.1001
Epoch [1/100], Step [420/1050], Loss: 0.1470
Epoch [1/100], Step [430/1050], Loss: 0.1393
Epoch [1/100], Step [440/1050], Loss: 0.0847
Epoch [1/100], Step [450/1050], Loss: 0.0712
Epoch [1/100], Step [460/1050], Loss: 0.0776
Epoch [1/100], Step [470/1050], Loss: 0.0746
Epoch [1/100], Step [480/1050], Loss: 0.0932
Epoch [1/100], Step [490/1050], Loss: 0.0783
Epoch [1/100], Step [500/1050], Loss: 0.0678
Epoch [1/100], Step [510/1050], Loss: 0.0857
Epoch [1/100], Step [520/1050], Loss: 0.1290
Epoch [1/100], Step [530/1050], Loss: 0.1072
Epoch [1/100], Step [540/1050], Loss: 0.1177
Epoch [1/100], Step [550/1050], Loss: 0.0768
Epoch [1/100], Step [560/1050], Loss: 0.0681
Epoch [1/100], Step [570/1050], Loss: 0.0960
Epoch [1/100], Step [580/1050], Loss: 0.0783
Epoch [1/100], Step [590/1050], Loss: 0.0810
Epoch [1/100], Step [600/1050], Loss: 0.0515
Epoch [1/100], Step [610/1050], Loss: 0.1402
Epoch [1/100], Step [620/1050], Loss: 0.1126
Epoch [1/100], Step [630/1050], Loss: 0.0892
Epoch [1/100], Step [640/1050], Loss: 0.0764
Epoch [1/100], Step [650/1050], Loss: 0.0534
Epoch [1/100], Step [660/1050], Loss: 0.0458
Epoch [1/100], Step [670/1050], Loss: 0.0792
Epoch [1/100], Step [680/1050], Loss: 0.0648
Epoch [1/100], Step [690/1050], Loss: 0.0595
Epoch [1/100], Step [700/1050], Loss: 0.0398
Epoch [1/100], Step [710/1050], Loss: 0.0491
Epoch [1/100], Step [720/1050], Loss: 0.0557
Epoch [1/100], Step [730/1050], Loss: 0.0625
Epoch [1/100], Step [740/1050], Loss: 0.0531
Epoch [1/100], Step [750/1050], Loss: 0.0530
Epoch [1/100], Step [760/1050], Loss: 0.0521
Epoch [1/100], Step [770/1050], Loss: 0.1246
Epoch [1/100], Step [780/1050], Loss: 0.1005
Epoch [1/100], Step [790/1050], Loss: 0.0507
Epoch [1/100], Step [800/1050], Loss: 0.0419
Epoch [1/100], Step [810/1050], Loss: 0.0751
Epoch [1/100], Step [820/1050], Loss: 0.0535
Epoch [1/100], Step [830/1050], Loss: 0.0445
Epoch [1/100], Step [840/1050], Loss: 0.0405
Epoch [1/100], Step [850/1050], Loss: 0.0395
Epoch [1/100], Step [860/1050], Loss: 0.1099
Epoch [1/100], Step [870/1050], Loss: 0.0426
Epoch [1/100], Step [880/1050], Loss: 0.0463
Epoch [1/100], Step [890/1050], Loss: 0.0529
Epoch [1/100], Step [900/1050], Loss: 0.0306
Epoch [1/100], Step [910/1050], Loss: 0.0351
Epoch [1/100], Step [920/1050], Loss: 0.0643
Epoch [1/100], Step [930/1050], Loss: 0.0410
Epoch [1/100], Step [940/1050], Loss: 0.0401
Epoch [1/100], Step [950/1050], Loss: 0.0514
Epoch [1/100], Step [960/1050], Loss: 0.0349
Epoch [1/100], Step [970/1050], Loss: 0.0442
Epoch [1/100], Step [980/1050], Loss: 0.0345
Epoch [1/100], Step [990/1050], Loss: 0.0337
Epoch [1/100], Step [1000/1050], Loss: 0.0394
Epoch [1/100], Step [1010/1050], Loss: 0.0317
Epoch [1/100], Step [1020/1050], Loss: 0.0821
Epoch [1/100], Step [1030/1050], Loss: 0.0306
Epoch [1/100], Step [1040/1050], Loss: 0.0472
Epoch [1/100], Step [1050/1050], Loss: 0.0471
Avg Validation MSE on all the 200 Val images is: 48990.98046875 
Avg Validation SSIM on all the 200 Val images is: 0.45941258157834974 
Epoch [2/100], Step [10/1050], Loss: 0.0463
